{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, the IUCN classes that form our response variable take the form of an ordinal system ranging from \"LC\" -- least concern -- to \"CR\" -- critically endangered. To move beyond binary classification, we can attempt to predict the specific class that each group belongs to. However, multiclass approaches will (by default) not account for the pseudo-numeric differences between our different classes.\n",
    "\n",
    "One approach is to adapt our learning objective to a binary classifier[by decomposing ordinal classes into a series of sequential tasks](https://www.cs.waikato.ac.nz/~eibe/pubs/ordinal_tech_report.pdf). This approach is conceptually similar to a one-vs-rest classifier:\n",
    "\n",
    "* $P(y_i = LC) = 1 - P(y_i > LC)$ \n",
    "* $P(y_i = NT) = P(y_i > LC) - P(y_i > NT)$ \n",
    "\n",
    "$\\dots$\n",
    "* $P(y_i = CR) = P(y_i > CR)$\n",
    "\n",
    "Assigned classes can then be generated by the maximum probability for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in datasets\n",
    "features_std = pd.read_csv(\"../data/features_std.csv\", index_col=0)\n",
    "features_imp = pd.read_csv(\"../data/features_imputed.csv\", index_col=0)\n",
    "y_full = features_std[\"Red List status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining new response variables \n",
    "def return_y_ordinal(y_dat):\n",
    "    resp_ordinal = pd.get_dummies(y_dat).drop(\"LC\", axis = 1)[[\"NT\", \"VU\", \"EN\", \"CR\"]]\n",
    "    resp_ordinal[\"EN\"] = resp_ordinal[\"EN\"] + resp_ordinal[\"CR\"]\n",
    "    resp_ordinal[\"VU\"] = resp_ordinal[\"VU\"] + resp_ordinal[\"EN\"]\n",
    "    resp_ordinal[\"NT\"] = resp_ordinal[\"NT\"] + resp_ordinal[\"VU\"]\n",
    "    \n",
    "    return(resp_ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Example of response structure:_\n",
    "\n",
    "An example visualization of this new response variable is presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NT</th>\n",
       "      <th>VU</th>\n",
       "      <th>EN</th>\n",
       "      <th>CR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red List status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VU</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NT</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NT  VU  EN  CR\n",
       "Red List status                \n",
       "LC                0   0   0   0\n",
       "VU                1   1   0   0\n",
       "EN                1   1   1   0\n",
       "CR                1   1   1   1\n",
       "NT                1   0   0   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y = return_y_ordinal(y_full)\n",
    "response_example = new_y.drop_duplicates()\n",
    "response_example.index = y_full[new_y.drop_duplicates().index]\n",
    "response_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Ordinal Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OrdinalClassifier(class_obj, x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    # First, run classifier on the lowest ordinal class\n",
    "    class_obj.fit(x_train, y_train[\"NT\"])\n",
    "    cat_1_trprob = class_obj.predict_proba(x_train)\n",
    "    cat_1_teprob = class_obj.predict_proba(x_test)\n",
    "    \n",
    "    # Repeat for second class\n",
    "    class_obj.fit(x_train, y_train[\"VU\"])\n",
    "    cat_2_trprob = class_obj.predict_proba(x_train)\n",
    "    cat_2_teprob = class_obj.predict_proba(x_test)\n",
    "    \n",
    "    # Repeat for third class\n",
    "    class_obj.fit(x_train, y_train[\"EN\"])\n",
    "    cat_3_trprob = class_obj.predict_proba(x_train)\n",
    "    cat_3_teprob = class_obj.predict_proba(x_test)\n",
    "    \n",
    "    # Repeat for fourth class\n",
    "    class_obj.fit(x_train, y_train[\"CR\"])\n",
    "    cat_4_trprob = class_obj.predict_proba(x_train)\n",
    "    cat_4_teprob = class_obj.predict_proba(x_test)\n",
    "    \n",
    "    # Returning ordinal class probabilities\n",
    "    train_probs = pd.DataFrame(np.vstack([cat_1_trprob[:,1], cat_2_trprob[:,1], \n",
    "                                          cat_3_trprob[:,1], cat_4_trprob[:,1]]).transpose())\n",
    "\n",
    "    test_probs = pd.DataFrame(np.vstack([cat_1_teprob[:,1], cat_2_teprob[:,1], \n",
    "                                         cat_3_teprob[:,1], cat_4_teprob[:,1]]).transpose())\n",
    "    \n",
    "    return(train_probs, test_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluating Ordinal Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(features_imp, y_full)\n",
    "\n",
    "classlist = [\"LC\", \"NT\", \"VU\", \"EN\", \"CR\"]\n",
    "mean_accuracy = []\n",
    "\n",
    "for c_val in [1,2,3,4,5]:\n",
    "    \n",
    "    accuracy = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(features_imp, y_full):\n",
    "\n",
    "        # Setting features\n",
    "        x_train = features_imp.loc[train_index]\n",
    "        x_test = features_imp.loc[test_index]\n",
    "\n",
    "        # Setting labels\n",
    "        y_train = return_y_ordinal(y_full[train_index])\n",
    "        y_test = return_y_ordinal(y_full[test_index])\n",
    "\n",
    "        # Standardizing numeric variables\n",
    "        stdscl = StandardScaler()\n",
    "        stdscl.fit(x_train.iloc[:,57:60])\n",
    "        x_train.iloc[:,57:60] = stdscl.transform(x_train.iloc[:,57:60])\n",
    "        x_test.iloc[:,57:60] = stdscl.transform(x_test.iloc[:,57:60])\n",
    "\n",
    "        # Running ordinal classification \n",
    "        classifier = SVC(kernel = \"rbf\", probability = True, C = c_val)\n",
    "        tp, te = OrdinalClassifier(classifier, x_train, y_train, x_test, y_test)\n",
    "\n",
    "        # Calculating predicted class probabilities\n",
    "        baseclass_prob = 1 - te.loc[:,0]\n",
    "        te.loc[:, 0] = te.loc[:, 0] - te.loc[:, 1]\n",
    "        te.loc[:, 1] = te.loc[:, 1] - te.loc[:, 2]\n",
    "        te.loc[:, 2] = te.loc[:, 2] - te.loc[:, 3]\n",
    "        \n",
    "        # Selecting max probability in each row as estimated class\n",
    "        pred_classes = pd.concat([baseclass_prob, te], ignore_index=True, axis = 1).idxmax(axis=1)\n",
    "\n",
    "        accuracy.append(accuracy_score(y_full[test_index], [classlist[pred] for pred in pred_classes]))\n",
    "        \n",
    "    print(\"CV run completed - C = %s\" % str(c_val))\n",
    "    \n",
    "    mean_accuracy.append(np.mean(accuracy))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,2,3,4,5], mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = x_test = features_imp\n",
    "y_train = y_test = return_y_ordinal(y_full)\n",
    "\n",
    "stdscl = StandardScaler()\n",
    "stdscl.fit(x_train.iloc[:,57:60])\n",
    "x_train.iloc[:,57:60] = stdscl.transform(x_train.iloc[:,57:60])\n",
    "        \n",
    "classifier = SVC(kernel = \"rbf\", probability = True, C = 1)\n",
    "tp, te = OrdinalClassifier(classifier, x_train, y_train, x_train, y_train)\n",
    "     \n",
    "baseclass_prob = 1 - te.loc[:,0]\n",
    "te.loc[:, 0] = te.loc[:, 0] - te.loc[:, 1]\n",
    "te.loc[:, 1] = te.loc[:, 1] - te.loc[:, 2]\n",
    "te.loc[:, 2] = te.loc[:, 2] - te.loc[:, 3]\n",
    "\n",
    "pred_classes = pd.concat([baseclass_prob, te], ignore_index=True, axis = 1).idxmax(axis=1)\n",
    "        \n",
    "cm = confusion_matrix(y_full, [classlist[pred] for pred in pred_classes], labels = classlist)\n",
    "cm = pd.DataFrame(cm)\n",
    "sns.heatmap(cm.div(cm.sum(axis=1), axis=0), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal classification with variable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(features_imp, y_full)\n",
    "\n",
    "classlist = [\"LC\", \"NT\", \"VU\", \"EN\", \"CR\"]\n",
    "mean_accuracy = []\n",
    "\n",
    "for c_val in [1,2,3,4,5]:\n",
    "    \n",
    "    accuracy = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(features_imp, y_full):\n",
    "\n",
    "        # Setting features\n",
    "        x_train = features_imp.loc[train_index]\n",
    "        x_test = features_imp.loc[test_index]\n",
    "\n",
    "        # Setting labels\n",
    "        y_train = return_y_ordinal(y_full[train_index])\n",
    "        y_test = return_y_ordinal(y_full[test_index])\n",
    "\n",
    "        # Standardizing numeric variables\n",
    "        stdscl = StandardScaler()\n",
    "        stdscl.fit(x_train.iloc[:,57:60])\n",
    "        x_train.iloc[:,57:60] = stdscl.transform(x_train.iloc[:,57:60])\n",
    "        x_test.iloc[:,57:60] = stdscl.transform(x_test.iloc[:,57:60])\n",
    "\n",
    "        # Running ordinal classification \n",
    "        classifier = SVC(kernel = \"rbf\", probability = True, C = c_val, class_weight = 'balanced')\n",
    "        tp, te = OrdinalClassifier(classifier, x_train, y_train, x_test, y_test)\n",
    "\n",
    "        # Calculating predicted class probabilities\n",
    "        baseclass_prob = 1 - te.loc[:,0]\n",
    "        te.loc[:, 0] = te.loc[:, 0] - te.loc[:, 1]\n",
    "        te.loc[:, 1] = te.loc[:, 1] - te.loc[:, 2]\n",
    "        te.loc[:, 2] = te.loc[:, 2] - te.loc[:, 3]\n",
    "        \n",
    "        # Selecting max probability in each row as estimated class\n",
    "        pred_classes = pd.concat([baseclass_prob, te], ignore_index=True, axis = 1).idxmax(axis=1)\n",
    "\n",
    "        accuracy.append(accuracy_score(y_full[test_index], [classlist[pred] for pred in pred_classes]))\n",
    "        \n",
    "    print(\"CV run completed - C = %s\" % str(c_val))\n",
    "    \n",
    "    mean_accuracy.append(np.mean(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,2,3,4,5], mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_test = features_imp\n",
    "y_train = y_test = return_y_ordinal(y_full)\n",
    "\n",
    "stdscl = StandardScaler()\n",
    "stdscl.fit(x_train.iloc[:,57:60])\n",
    "x_train.iloc[:,57:60] = stdscl.transform(x_train.iloc[:,57:60])\n",
    "        \n",
    "classifier = SVC(kernel = \"rbf\", probability = True, C = 1, class_weight = 'balanced')\n",
    "tp, te = OrdinalClassifier(classifier, x_train, y_train, x_train, y_train)\n",
    "     \n",
    "baseclass_prob = 1 - te.loc[:,0]\n",
    "te.loc[:, 0] = te.loc[:, 0] - te.loc[:, 1]\n",
    "te.loc[:, 1] = te.loc[:, 1] - te.loc[:, 2]\n",
    "te.loc[:, 2] = te.loc[:, 2] - te.loc[:, 3]\n",
    "\n",
    "pred_classes = pd.concat([baseclass_prob, te], ignore_index=True, axis = 1).idxmax(axis=1)\n",
    "        \n",
    "cm = confusion_matrix(y_full, [classlist[pred] for pred in pred_classes], labels = classlist)\n",
    "cm = pd.DataFrame(cm)\n",
    "sns.heatmap(cm.div(cm.sum(axis=1), axis=0), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(features_imp, y_full)\n",
    "\n",
    "classlist = [\"LC\", \"NT\", \"VU\", \"EN\", \"CR\"]\n",
    "mean_accuracy = []\n",
    "\n",
    "for c_val in [1,2,3,4,5]:\n",
    "    \n",
    "    accuracy = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(features_imp, y_full):\n",
    "\n",
    "        # Setting features\n",
    "        x_train = features_imp.loc[train_index]\n",
    "        x_test = features_imp.loc[test_index]\n",
    "\n",
    "        # Setting labels\n",
    "        y_train = y_full[train_index]\n",
    "        y_test = y_full[test_index]\n",
    "\n",
    "        # Standardizing numeric variables\n",
    "        stdscl = StandardScaler()\n",
    "        stdscl.fit(x_train.iloc[:,57:60])\n",
    "        x_train.iloc[:,57:60] = stdscl.transform(x_train.iloc[:,57:60])\n",
    "        x_test.iloc[:,57:60] = stdscl.transform(x_test.iloc[:,57:60])\n",
    "\n",
    "        # Running ordinal classification \n",
    "        classifier = SVC(kernel = \"rbf\", probability = True, C = c_val, \n",
    "                         class_weight = 'balanced', decision_function_shape = \"ovr\")\n",
    "        classifier.fit(x_train, y_train)\n",
    "        \n",
    "        # Selecting max probability in each row as estimated class\n",
    "        pred_classes = classifier.predict(x_test)\n",
    "\n",
    "        accuracy.append(accuracy_score(y_test, pred_classes))\n",
    "        \n",
    "    print(\"CV run completed - C = %s\" % str(c_val))\n",
    "    \n",
    "    mean_accuracy.append(np.mean(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,2,3,4,5], mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_test = features_imp\n",
    "y_train = y_test = y_full\n",
    "\n",
    "stdscl = StandardScaler()\n",
    "stdscl.fit(x_train.iloc[:,57:60])\n",
    "x_train.iloc[:,57:60] = stdscl.transform(x_train.iloc[:,57:60])\n",
    "        \n",
    "classifier = SVC(kernel = \"rbf\", probability = True, C = 1, \n",
    "                         class_weight = 'balanced', decision_function_shape = \"ovr\")\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "pred_classes = classifier.predict(x_test)\n",
    "        \n",
    "cm = confusion_matrix(y_full, pred_classes, labels = classlist)\n",
    "cm = pd.DataFrame(cm)\n",
    "sns.heatmap(cm.div(cm.sum(axis=1), axis=0), annot = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
